{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "Summary:\n",
    "- Developed LightningDataModule to handle dataset and dataloader for train,val,test sets\n",
    "- Apply appropriate transformation for augmentation (also normalization)\n",
    "- Reuse metrics from previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.json', 'valid.json', 'train.csv', 'test.csv', 'train.json', 'segmentation', '.ipynb_checkpoints', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "m_path = '/home/tungnguyendinh/.fastai/data/pascal_2007/'\n",
    "print(os.listdir(m_path))\n",
    "\n",
    "#Define classes and encode/decode functions\n",
    "\n",
    "VOC_CLASSES = (\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "    'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "    'cow', 'diningtable', 'dog', 'horse',\n",
    "    'motorbike', 'person', 'pottedplant',\n",
    "    'sheep', 'sofa', 'train', 'tvmonitor'\n",
    ")\n",
    "\n",
    "def encode_label(labels, classes = VOC_CLASSES):\n",
    "    target = torch.zeros(len(classes))\n",
    "    for l in labels:\n",
    "        idx = classes.index(l)\n",
    "        target[idx] = 1\n",
    "    return target\n",
    "\n",
    "def decode_target(target, threshold = 0.5, classes = VOC_CLASSES):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if (x >= threshold):\n",
    "            result.append(classes[i])\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "#Create Custom dataset class for Pascal_2007\n",
    "class PascalDataset(Dataset):\n",
    "    def __init__(self, img_dir, annotations_file, transform=None, target_transform=None, is_train = False, is_valid = False):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        if is_train:\n",
    "            self.img_labels = self.img_labels[~self.img_labels[\"is_valid\"]]\n",
    "        if is_valid:\n",
    "            self.img_labels = self.img_labels[self.img_labels[\"is_valid\"]]\n",
    "            \n",
    "                \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1].split(\" \")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, encode_label(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PascalVOCDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, data_dir):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = [0.457342265910642, 0.4387686270106377, 0.4073427106250871]\n",
    "        self.std = [0.26753769276329037, 0.2638145880487105, 0.2776826934044154]  \n",
    "        self.train_transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((300, 300)),\n",
    "                transforms.RandomChoice([\n",
    "                                        transforms.ColorJitter(brightness=(0.9, 1.1)),\n",
    "                                        transforms.RandomGrayscale(p = 0.25)\n",
    "                                        ]),\n",
    "                transforms.RandomHorizontalFlip(p = 0.25),\n",
    "                transforms.RandomRotation(25),\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(mean = self.mean, std = self.std),\n",
    "                ])\n",
    "        self.eval_transform = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize((300, 300)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean = self.mean, std = self.std)\n",
    "                   ])\n",
    "        \n",
    "    def setup(self):\n",
    "        stage = \"train\"\n",
    "        self.voc_train = PascalDataset(f\"{self.data_dir}/{stage}\", f\"{self.data_dir}/{stage}.csv\", transform=self.train_transform, is_train= True)\n",
    "        self.voc_val = PascalDataset(f\"{self.data_dir}/{stage}\", f\"{self.data_dir}/{stage}.csv\", transform=self.eval_transform, is_valid = True) \n",
    "        stage = \"test\"                       \n",
    "        self.voc_test = PascalDataset(f\"{self.data_dir}/{stage}\", f\"{self.data_dir}/{stage}.csv\", transform=self.eval_transform)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        self.setup()\n",
    "        return DataLoader(self.voc_train, self.batch_size)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.voc_val, self.batch_size)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.voc_test, self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "voc = PascalVOCDataModule(BATCH_SIZE, m_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def Accuracy_n_HammingScore(y_pred, y_true):\n",
    "    y_pred = torch.round(y_pred)\n",
    "    label = np.asarray(y_true.cpu())\n",
    "    prob = np.asarray(y_pred.cpu())\n",
    "    batch_size = label.shape[0]\n",
    "    acc = 0\n",
    "    hl = 0\n",
    "    for i in range(batch_size):\n",
    "        acc += accuracy_score(prob[i], label[i], normalize=True)\n",
    "        hl += sum(torch.logical_and(\n",
    "            y_true[i], y_pred[i])) / sum(torch.logical_or(y_true[i], y_pred[i]))\n",
    "    acc /= batch_size\n",
    "    hl /= batch_size\n",
    "    acc = torch.Tensor([acc])\n",
    "    return acc, hl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building \n",
    "Summary:\n",
    "- Rebuild Model class (ResNet) with pytorch lighning module\n",
    "- Make use of functions such as training_step, validation_step within LightningModule to organize training and validating processes\n",
    "- Achieved similar (if not better) result with model from pure PyTorch\n",
    "- Make use of recall to log metrics and filter visualization to TensorBoard, also load pretrained weights from previous exercise\n",
    "- Use localhost:6007 on any browser to view TensorBoard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.types import EPOCH_OUTPUT\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels,\n",
    "                               kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "\n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "\n",
    "        # downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        # add identity\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels,\n",
    "                               kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "        x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return\n",
    "\n",
    "\n",
    "class ResNet(pl.LightningModule):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(\n",
    "            ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(\n",
    "            ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(\n",
    "            ResBlock, layer_list[3], planes=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "    \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion,\n",
    "                          kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(ResBlock(self.in_channels, planes,\n",
    "                      i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "\n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=1e-3, momentum=0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 12, eta_min=0, last_epoch=-1)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "\n",
    "        pred = self.forward(X)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        tmp_pred = nn.Sigmoid()(pred).detach()\n",
    "        tmp_y    = y.detach()\n",
    "        acc, hl = Accuracy_n_HammingScore(tmp_pred, tmp_y)\n",
    "        batch_dictionary = {\n",
    "            \"loss\" : loss,\n",
    "            \"acc\"  : acc,\n",
    "            \"hl\"   : hl\n",
    "        }\n",
    "        if (batch_idx % 50 == 0):    \n",
    "            print(f\"loss: {loss:>7f}, training accuracy: {100*acc.item():>0.1f}%, hamming score: {100*hl.item():>0.1f}% Batch: {batch_idx}\")       \n",
    "             \n",
    "        return batch_dictionary\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        X, y = val_batch\n",
    "        pred = self.forward(X)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        pred = nn.Sigmoid()(pred)\n",
    "        acc, hl = Accuracy_n_HammingScore(pred, y)\n",
    "        batch_dictionary = {\n",
    "            \"loss\" : loss,\n",
    "            \"acc\"  : acc,\n",
    "            \"hl\"   : hl\n",
    "        }\n",
    "        return batch_dictionary\n",
    "                    \n",
    "    \n",
    "def ResNet34(num_classes, channels=3):\n",
    "    return ResNet(Block, [3, 4, 6, 3], num_classes, channels)\n",
    "\n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes, channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class ResNetCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_outputs = []\n",
    "        self.val_outputs = []\n",
    "    \n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        pretrained_dict = torch.load('runs/ResNet50_Pretrained_Standardized_exp0/model.pth')\n",
    "        model_dict = pl_module.state_dict()\n",
    "        pretrained_dict = {k:v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        pl_module.load_state_dict(model_dict)\n",
    "        \n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, unused = 0):\n",
    "        self.train_outputs.append(outputs)\n",
    "        \n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, unused=0):\n",
    "        self.val_outputs.append(outputs)\n",
    "    \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        avg_loss = torch.stack([x['loss'] for x in self.train_outputs]).mean()\n",
    "        avg_acc  = torch.stack([x['acc'] for x in self.train_outputs]).mean()\n",
    "        avg_hl   = torch.stack([x['hl'] for x in self.train_outputs]).mean()\n",
    "        \n",
    "        pl_module.logger.experiment.add_scalar(\"Loss/train\",\n",
    "                                          avg_loss,\n",
    "                                          pl_module.current_epoch)\n",
    "        \n",
    "        pl_module.logger.experiment.add_scalar(\"Accuracy/train\",\n",
    "                                          avg_acc,\n",
    "                                          pl_module.current_epoch)\n",
    "        \n",
    "        pl_module.logger.experiment.add_scalar(\"HammingScore/train\",\n",
    "                                          avg_hl,\n",
    "                                          pl_module.current_epoch)\n",
    "            \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        avg_loss = torch.stack([x['loss'] for x in self.val_outputs]).mean()\n",
    "        avg_acc  = torch.stack([x['acc'] for x in self.val_outputs]).mean()\n",
    "        avg_hl   = torch.stack([x['hl'] for x in self.val_outputs]).mean()\n",
    "\n",
    "        #Logging to tensorboard\n",
    "        pl_module.logger.experiment.add_scalar(\"Loss/validation\",\n",
    "                                          avg_loss,\n",
    "                                          pl_module.current_epoch)\n",
    "        \n",
    "        pl_module.logger.experiment.add_scalar(\"Accuracy/validation\",\n",
    "                                          avg_acc,\n",
    "                                          pl_module.current_epoch)\n",
    "        \n",
    "        pl_module.logger.experiment.add_scalar(\"HammingScore/validation\",\n",
    "                                          avg_hl,\n",
    "                                          pl_module.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "   | Name        | Type              | Params\n",
      "---------------------------------------------------\n",
      "0  | loss_fn     | BCEWithLogitsLoss | 0     \n",
      "1  | conv1       | Conv2d            | 9.4 K \n",
      "2  | batch_norm1 | BatchNorm2d       | 128   \n",
      "3  | relu        | ReLU              | 0     \n",
      "4  | max_pool    | MaxPool2d         | 0     \n",
      "5  | layer1      | Sequential        | 217 K \n",
      "6  | layer2      | Sequential        | 1.2 M \n",
      "7  | layer3      | Sequential        | 7.1 M \n",
      "8  | layer4      | Sequential        | 15.0 M\n",
      "9  | avgpool     | AdaptiveAvgPool2d | 0     \n",
      "10 | fc          | Linear            | 41.0 K\n",
      "---------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.302    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/314 [00:00<?, ?it/s] loss: 0.154128, training accuracy: 94.4%, hamming score: 31.2% Batch: 0\n",
      "Epoch 0:  16%|█▌        | 50/314 [00:27<02:25,  1.81it/s, loss=0.193, v_num=9]loss: 0.207214, training accuracy: 92.8%, hamming score: 10.9% Batch: 50\n",
      "Epoch 0:  32%|███▏      | 100/314 [00:54<01:57,  1.83it/s, loss=0.183, v_num=9]loss: 0.176365, training accuracy: 94.1%, hamming score: 35.4% Batch: 100\n",
      "Epoch 0:  48%|████▊     | 150/314 [01:22<01:30,  1.82it/s, loss=0.192, v_num=9]loss: 0.148910, training accuracy: 94.4%, hamming score: 36.7% Batch: 150\n",
      "Epoch 0: 100%|██████████| 314/314 [02:30<00:00,  2.08it/s, loss=0.184, v_num=9]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(20)\n",
    "logger = TensorBoardLogger('runs', name='ResNet50_Pretrained_Lightning')\n",
    "trainer = pl.Trainer(accelerator=\"gpu\"\n",
    "                     , max_epochs=1\n",
    "                     , devices=[1]\n",
    "                     , progress_bar_refresh_rate=1\n",
    "                     , logger=logger\n",
    "                     , callbacks=[ResNetCallback()]\n",
    "                     )\n",
    "trainer.fit(model, voc.train_dataloader(), voc.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/torch/_jit_internal.py:505: LightningDeprecationWarning: The `LightningModule.loaded_optimizer_states_dict` property is deprecated in v1.4 and will be removed in v1.6.\n",
      "  item = getattr(mod, name)\n",
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/torch/_jit_internal.py:505: LightningDeprecationWarning: The `LightningModule.model_size` property was deprecated in v1.5 and will be removed in v1.7. Please use the `pytorch_lightning.utilities.memory.get_model_size_mb`.\n",
      "  item = getattr(mod, name)\n"
     ]
    }
   ],
   "source": [
    "sampleImg = torch.rand((1,3,300,300))\n",
    "logger.experiment.add_graph(model, sampleImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makegrid(output, numrows):\n",
    "    outer = (torch.Tensor.cpu(output).detach())\n",
    "    plt.figure(figsize=(20,5))\n",
    "    b = np.array([]).reshape(0, outer.shape[2])\n",
    "    c = np.array([]).reshape(numrows*outer.shape[2], 0)\n",
    "    i=0\n",
    "    j=0\n",
    "    while(i<outer.shape[1]):\n",
    "        img = outer[0][i]\n",
    "        b = np.concatenate((img,b), axis=0)\n",
    "        j += 1\n",
    "        if (j == numrows):\n",
    "            c = np.concatenate((c,b), axis=1)\n",
    "            b = np.array([]).reshape(0, outer.shape[2])\n",
    "            j = 0\n",
    "        i += 1\n",
    "    return c\n",
    "\n",
    "def ActivationMaps(pl_module, x, device = 1):\n",
    "        pl_module.logger.experiment.add_image(\"input\", torch.Tensor.cpu(x[0]), pl_module.current_epoch, dataformats=\"CHW\")\n",
    "        \n",
    "        out = pl_module.relu(pl_module.batch_norm1(pl_module.conv1(x)))\n",
    "        out = pl_module.max_pool(out)\n",
    "        c = makegrid(out, 4)\n",
    "        pl_module.logger.experiment.add_image(\"layer0\", c, pl_module.current_epoch, dataformats=\"HW\")\n",
    "        \n",
    "        out = pl_module.layer1(out)\n",
    "        c = makegrid(out, 4)\n",
    "        pl_module.logger.experiment.add_image(\"layer1\", c, pl_module.current_epoch, dataformats=\"HW\")\n",
    "        \n",
    "        out = pl_module.layer2(out)\n",
    "        c = makegrid(out, 4)\n",
    "        pl_module.logger.experiment.add_image(\"layer2\", c, pl_module.current_epoch, dataformats=\"HW\")\n",
    "\n",
    "        out = pl_module.layer3(out)\n",
    "        c = makegrid(out, 4)\n",
    "        pl_module.logger.experiment.add_image(\"layer3\", c, pl_module.current_epoch, dataformats=\"HW\")\n",
    "\n",
    "        out = pl_module.layer4(out)\n",
    "        c = makegrid(out, 4)\n",
    "        pl_module.logger.experiment.add_image(\"layer4\", c, pl_module.current_epoch, dataformats=\"HW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img = next(iter(voc.train_dataloader()))[0]\n",
    "ActivationMaps(model, sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/datnguyenthanh/datnt_venv/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.13.0 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir=runs --port=6007"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datnt_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
